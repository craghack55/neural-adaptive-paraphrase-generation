\relax 
\providecommand\hyper@newdestlabel[2]{}
\AC@reset@newl@bel
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\providecommand \oddpage@label [2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\newlabel{sec:abstract}{{}{III}{Abstract}{section*.1}{}}
\citation{par4sim}
\citation{zhao}
\citation{paszke}
\citation{Prakashetal}
\citation{brad}
\citation{Guptaetal}
\citation{concept}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{introduction}{{1}{2}{Introduction}{chapter.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Human in the loop data acquisition}}{3}{figure.1.1}}
\citation{par4sim}
\citation{par4sim}
\citation{par4sim}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces An interactive human-in-the-loop application for text simplification \cite  {par4sim}. Target words to be simplified are highlighted and user is provided with a list of candidate words to choose from. Candidate words are generated and ranked by the system/model.}}{4}{figure.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Thesis Organization}{5}{section.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Research Questions}{6}{section.1.2}}
\citation{siriam}
\citation{hannun}
\citation{cho}
\citation{Vinyalsetal}
\citation{Prakashetal}
\citation{Guptaetal}
\citation{Lietal}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Related Work}{7}{section.1.3}}
\citation{trivedi}
\citation{Yimam:2016aa}
\citation{par4sim}
\citation{parisi}
\citation{mou}
\citation{zoph}
\citation{brad}
\citation{yoon}
\citation{shen}
\citation{zhao}
\citation{rubio}
\citation{zhao}
\citation{paszke}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Methods}{10}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{methods}{{2}{10}{Methods}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Recurrent Neural Networks}{10}{section.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Long Short-Term Memory}{10}{section.2.2}}
\citation{paszke}
\citation{Vinyalsetal}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Recurrent neural network expanding through time steps \cite  {zhao}}}{11}{figure.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces A typical LSTM cell \cite  {paszke}}}{12}{figure.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Sequence to Sequence Model Architecture}{12}{section.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Sequence to sequence learning with encoder-decoder framework}}{13}{figure.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Incremental Learning}{13}{section.2.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Transfer Learning}{13}{section.2.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Idea behind transfer learning}}{14}{figure.2.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Active Learning}{14}{section.2.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Pool based active learning scheme}}{15}{figure.2.5}}
\citation{Prakashetal}
\citation{bahdanau}
\citation{Prakashetal}
\citation{msrp}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Adaptive Learning Strategies}{16}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{approach}{{3}{16}{Adaptive Learning Strategies}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Model Details}{16}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Datasets and Evaluation Metric}{16}{section.3.2}}
\citation{mscoco}
\citation{ppdb}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Stacked LSTM based model \cite  {Prakashetal}}}{17}{figure.3.1}}
\citation{Papinenietal}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Example paraphrase pairs}}{18}{table.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Experimental Setups}{18}{section.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Incremental Learning Strategies}{18}{section.3.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Incremental learning with data pooling. The model uses data from all prevous iterations, hyperparameters re-initialized and weights are transferred through iterations.}}{20}{figure.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Incremental Learning with Data Pooling (IL1)}{20}{subsection.3.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Incremental learning without data pooling. The model only uses data from latest iteration, hyperparameters re-initialized and weights are transferred through iterations.}}{21}{figure.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Incremental Learning without Data Pooling (IL2)}{21}{subsection.3.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Incremental Learning with Network Expansion (IL-NE)}{22}{subsection.3.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Incremental Learning Baseline (IL3)}{22}{subsection.3.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.5}Model Regularization in Incremental Learning}{22}{subsection.3.4.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Incremental learning baseline. The model is trained from scratch for each iteration, no knowledge transfer involved.}}{23}{figure.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Transfer Learning Strategies}{23}{section.3.5}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Active Learning Strategies}{25}{section.3.6}}
\citation{rubio}
\citation{shen}
\citation{brad}
\citation{brad}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results}{28}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{results}{{4}{28}{Results}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Neural Paraphrase Generation with Incremental Learning}{28}{section.4.1}}
\citation{Guptaetal}
\citation{Guptaetal}
\citation{Guptaetal}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces BLEU scores of incremental learning on MSR dataset. Each column represents an iteration, first row shows what percent of the dataset is used in that iteration. Each row except the last represents the performance of a particular learning strategy which are described in Chapter 3. The last column represents the results from \cite  {brad}.}}{29}{table.4.1}}
\newlabel{table:4.1}{{4.1}{29}{BLEU scores of incremental learning on MSR dataset. Each column represents an iteration, first row shows what percent of the dataset is used in that iteration. Each row except the last represents the performance of a particular learning strategy which are described in Chapter 3. The last column represents the results from \cite {brad}}{table.4.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces BLEU scores of incremental learning on QUORA dataset. Each column represents an iteration, first row shows what percent of the dataset is used in that iteration. Each row except the last represents the performance of a particular learning strategy which are described in Chapter 3. The last column represents the results from \cite  {Guptaetal}.}}{29}{table.4.2}}
\newlabel{table:4.2}{{4.2}{29}{BLEU scores of incremental learning on QUORA dataset. Each column represents an iteration, first row shows what percent of the dataset is used in that iteration. Each row except the last represents the performance of a particular learning strategy which are described in Chapter 3. The last column represents the results from \cite {Guptaetal}}{table.4.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces BLEU scores of incremental learning with data pooling on QUORA dataset with different dropout probabilities. Each column except the first represents an iteration, first row shows what percent of the dataset is used in that iteration. First column represents the dropout probabilities.}}{30}{table.4.3}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces BLEU scores of incremental learning baseline on QUORA dataset with different dropout probabilities. Each column except the first represents an iteration, first row shows what percent of the dataset is used in that iteration. First column represents the dropout probabilities.}}{31}{table.4.4}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces BLEU scores of incremental learning without data pooling on QUORA dataset with different number of epochs. Each column except the first represents an iteration, first row shows what percent of the dataset is used in that iteration. First column represents the number of epochs.}}{31}{table.4.5}}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces BLEU scores of supervised learning without data pooling on QUORA dataset. Each column represents an iteration, first row shows how much percent of the dataset is used in that iteration. Each iteration trained separately.}}{32}{table.4.6}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces BLEU scores of different transfer learning methods on MSR dataset. First row represents the source datasets. Rest of the rows represents transfer methods and corresponding BLEU scores.}}{33}{table.4.7}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Neural Paraphrase Generation with Transfer Learning}{33}{section.4.2}}
\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces BLEU scores of different transfer learning methods on QUORA-120K and QUORA-48K datasets when MSCOCO dataset used as source. First row represents the target datasets. Rest of the rows represents transfer methods and corresponding BLEU scores.}}{34}{table.4.8}}
\@writefile{lot}{\contentsline {table}{\numberline {4.9}{\ignorespaces BLEU scores of incremental learning with and without network expansion on QUORA dataset. Each column represents an iteration, first row shows what percent of the dataset is used in that iteration. IL2-NE2 represents incremental learning without data pooling and layer freezing.}}{35}{table.4.9}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Neural Paraphrase Generation with Active Learning}{35}{section.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Neural Paraphrase Generation with Network Expansion}{35}{section.4.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Combining Different Strategies}{35}{section.4.5}}
\@writefile{lot}{\contentsline {table}{\numberline {4.10}{\ignorespaces BLEU scores of incremental learning with data pooling trained with different transfer methods on MSR dataset. Each column except the first represents an iteration, first row shows what percent of the dataset is used in that iteration. Last row represents supervised learning.}}{36}{table.4.10}}
\@writefile{lot}{\contentsline {table}{\numberline {4.11}{\ignorespaces BLEU scores of different incremental learning strategies trained with INIT transfer method on MSR dataset. Each column except the first represents an iteration, first row shows what percent of the dataset is used in that iteration. Last row represents supervised learning.}}{37}{table.4.11}}
\@writefile{lot}{\contentsline {table}{\numberline {4.12}{\ignorespaces BLEU scores of incremental learning with data pooling trained with transfer methods INIT and Freeze 1 layer on QUORA dataset. Each column except the first represents an iteration, first row shows what percent of the dataset is used in that iteration. Last row represents incremental learning without transfer.}}{37}{table.4.12}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Discussion}{38}{section.4.6}}
\citation{brad}
\citation{mou}
\bibstyle{apalike}
\bibdata{thesis}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion and Future Work}{41}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{conclusion}{{5}{41}{Conclusion and Future Work}{chapter.5}{}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{41}{section*.5}}
\bibcite{bahdanau}{Bahdanau et~al., 2014}
\bibcite{brad}{Brad and Rebedea, 2017}
\bibcite{cho}{Cho et~al., 2014}
\bibcite{msrp}{Dolan and Brockett, 2005}
\bibcite{rubio}{Gonz\'{a}lez-Rubio et~al., 2012}
\bibcite{Guptaetal}{Gupta et~al., 2017}
\bibcite{hannun}{Hannun et~al., 2014}
\bibcite{Lietal}{Li et~al., 2017}
\bibcite{mscoco}{Lin et~al., 2014}
\bibcite{mou}{Mou et~al., 2016}
\bibcite{Papinenietal}{Papineni et~al., 2002}
\bibcite{parisi}{Parisi et~al., 2018}
\bibcite{paszke}{Paszke, 2016}
\bibcite{ppdb}{Pavlick et~al., 2015}
\bibcite{Prakashetal}{Prakash et~al., 2016}
\bibcite{shen}{Shen et~al., 2017}
\bibcite{siriam}{Sriram et~al., 2017}
\bibcite{Vinyalsetal}{Sutskever et~al., 2014}
\bibcite{trivedi}{Trivedi et~al., 2017}
\bibcite{par4sim}{Yimam and Biemann, 2018}
\bibcite{Yimam:2016aa}{Yimam et~al., 2016}
\bibcite{yoon}{Yoon et~al., 2017}
\bibcite{zhao}{Zhao, 2017}
\bibcite{concept}{Zliobaite, 2010}
\bibcite{zoph}{Zoph et~al., 2016}
\newlabel{sec:urheber}{{5}{45}{Erkl\"arung der Urheberschaft}{chapter*.7}{}}
\newlabel{sec:urheber}{{5}{47}{Erkl\"arung zur Ver\"offentlichung}{chapter*.8}{}}
